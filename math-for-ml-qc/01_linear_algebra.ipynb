{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nF_N9U9pXRN"
   },
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFEk1hwsvjh-"
   },
   "source": [
    "This section includes setup code for the remaining sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --user -qq wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OGWHqVCZGuGk",
    "outputId": "4b3030f0-dff8-49de-bbb1-c3006a008206"
   },
   "outputs": [],
   "source": [
    "# importing from standard library\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# importing libraries\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import torch\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "%env WANDB_NOTEBOOK_NAME=\"nb\" \n",
    "\n",
    "# importing course-specific modules\n",
    "import util\n",
    "import linearalgebra as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1o1BANRBep-E"
   },
   "source": [
    "### Automated Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOZ6bEO5pvdp"
   },
   "source": [
    "This cell sets up an automatic feedback system, or \"autograder\",\n",
    "and (anonymously) reports your progress to the\n",
    "[Weights & Biases](http://wandb.com/)\n",
    "project page that appears in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfrciZac2HBk"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    grader\n",
    "except NameError:\n",
    "    grader = util.WandbTrackedOK(\n",
    "        \"charlesfrye\", \"linearalgebra/config\", \"linearalgebra\", \"linearalgebra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G1HeCVWFWXNu"
   },
   "source": [
    "Throughout this notebook, you will see cells like the one below.\n",
    "\n",
    "They immediately follow exercises and will run some tests to check\n",
    "whether your solutions are correct.\n",
    "They are included because quick, specific feedback has been\n",
    "[shown to improve learning](https://files.eric.ed.gov/fulltext/EJ786608.pdf).\n",
    "\n",
    "Run the cell below to see an example of the grader output\n",
    "for an incorrect question.\n",
    "The output will include some setup code,\n",
    "then a series of tests and, towards the bottom, the lines\n",
    "```\n",
    "# Error: expected\n",
    "# x\n",
    "# but got\n",
    "# y\n",
    "```\n",
    "where `x` is the output the autograder expected,\n",
    "and the lines `y` following show what was produced by your code.\n",
    "\n",
    "This particular test is failing because the `dimensions` variable is not defined.\n",
    "Try defining `dimensions = []` and `dimensions = {}`\n",
    "and see how the output changes.\n",
    "You'll see how to correctly answer this question in the following section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "iqlc51lX1uwC",
    "outputId": "f1a314f3-b21c-4fc8-e19b-ea1e8b747964"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOvkwqdHHKQ2"
   },
   "source": [
    "# Section 1. Programming with Arrays: Shapes, Dimensions, and Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBYIeXLWualG"
   },
   "source": [
    "This section includes a series of exercises on working with linear algebra in Python.\n",
    "\n",
    "See [this 20 min talk](https://www.youtube.com/watch?v=F3lG9_SxCXk),\n",
    "\"Linear Algebra is Not Like Algebra\",\n",
    "for an introduction to the approach taken in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbqP4KXFcXyU"
   },
   "source": [
    "## Shapes and Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHwmdRqD7v9C"
   },
   "source": [
    "_Note_: The primary library for working with arrays in Python is `numpy`,\n",
    "which is typically `import`ed `as np` (see above).\n",
    "This notebook is not a full introduction to `numpy`.\n",
    "If you'd like a more in-depth tutorial,\n",
    "check out\n",
    "[this online tutorial](https://cs231n.github.io/python-numpy-tutorial/)\n",
    "from a Stanford course on neural networks.\n",
    "\n",
    "The cell below creates four arrays, then prints them out.\n",
    "\n",
    "After reviewing the code and the printed arrays,\n",
    "store the _dimensions_ of these arrays in a dictionary\n",
    "called `dimensions`.\n",
    "Use the variable names as keys.\n",
    "Then execute the cell with `grader.grade` to check your answer.\n",
    "\n",
    "This is an exercise.\n",
    "Exercises in this notebook will be indicated with the format below:\n",
    "\n",
    "#### Store the dimensions of these arrays in a dictionary called `dimensions`.\n",
    "\n",
    "Remember that you can add new cells to this notebook,\n",
    "where you can write additional code.\n",
    "This is particularly helpful when you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcUS8_AV7w3a"
   },
   "outputs": [],
   "source": [
    "A = np.array([1])\n",
    "B = np.array([[1, 2]])\n",
    "C = np.array([[1, 0], [0, 1]])\n",
    "D = np.array([[3], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "KyQcljVn8Fwz",
    "outputId": "75b121fc-c7c2-40d0-93b5-2998a4221809"
   },
   "outputs": [],
   "source": [
    "print(A, \"\\n\"), print(B, \"\\n\"), print(C, \"\\n\"), print(D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1iY2vOj7_wj"
   },
   "outputs": [],
   "source": [
    "dimensions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "EQfzesJH8RDe",
    "outputId": "ab014b62-897e-4883-e19d-0d9be641d3cf"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5ZrMzCOvHA5"
   },
   "source": [
    "#### Now, do the same with the _shapes_ of the arrays in a dictionary called `shapes`.\n",
    "\n",
    "The shape of an array is an ordered collection of the number of entries in each dimension.\n",
    "\n",
    "_Note_: shapes are usually represented with tuples in Python: e.g. `(x, y, z)`\n",
    "for an array of three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pgtWZnT8Zzk"
   },
   "outputs": [],
   "source": [
    "shapes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqYpS3a189kT"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXhW-Ge2u11n"
   },
   "source": [
    "Heads up:\n",
    "if you want to know the dimension and shape of an array,\n",
    "use the `.ndim` and `.shape` attributes.\n",
    "Very handy to put in `print`s or `assert`s while debugging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kK6JOk9N8MXS"
   },
   "outputs": [],
   "source": [
    "A.ndim, B.ndim, C.ndim, D.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpCi_eQT8gt8"
   },
   "outputs": [],
   "source": [
    "A.shape, B.shape, C.shape, D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRTdEBjqvybL"
   },
   "source": [
    "The _transpose_ is a common matrix operation.\n",
    "It's so common, it gets represented as an attribute _and_\n",
    "as a single-letter to boot!\n",
    "\n",
    "The transpose of a matrix `M` is written in `numpy` as `M.T`.\n",
    "\n",
    "The cell below prints the transposes of three of the matrices above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFtVyBUw8-d2"
   },
   "outputs": [],
   "source": [
    "print(B.T), print(C.T), print(D.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRTdEBjqvybL"
   },
   "source": [
    "#### Q Can you describe, in your own words, what the transpose does?\n",
    "\n",
    "_Note_: this is an \"in-line\" question.\n",
    "These discussion-style questions will be inter-mingled with coding exercises,\n",
    "but they do not have any attached automatic grading, for obvious reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNBzmLANwcg5"
   },
   "source": [
    "Transposition is closely related to matrix shape.\n",
    "\n",
    "#### Define a function, `shape_of_transpose`, that takes in a `matrix` and returns the shape of the transpose of the matrix.\n",
    "\n",
    "Try doing this two ways: with and without transposing `matrix` inside the body of the function.\n",
    "\n",
    "Then, execute the `grader.grade` cell to check your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFRGECsywLRj"
   },
   "outputs": [],
   "source": [
    "# define the function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUeIApHh9A-U"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zoMQZ1BWwekZ"
   },
   "source": [
    "Fun fact: the transpose is also a linear operation,\n",
    "and so can be represented by a tensor!\n",
    "That fact is not useful for implementations of transposition,\n",
    "but it is incredibly useful for linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoSQY_IGyyh7"
   },
   "source": [
    "## Composition and Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dG-0ZLv-A-EK"
   },
   "source": [
    "You're looking through a fellow developer's code and notice that in\n",
    "`their_pipeline`, which appears below,\n",
    "a large amount of data is being passed through four successive matrix operations: in order, the data vectors are multiplied by `W`, then `X`, then `Y`, and finally by `Z`.\n",
    "\n",
    "For simplicity's sake, you want to collapse these four multiplications\n",
    "into one operation, call it `V`.\n",
    "\n",
    "#### Use `np.matmul` to define `V`.\n",
    "\n",
    "_Note_: the `@` symbol can be used, in later versions of Python 3,\n",
    "to represent `np.matmul` just like `*` represents multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O64lKhHVAPfv"
   },
   "outputs": [],
   "source": [
    "W = np.array([[1, 2], [-1, 1]])\n",
    "X = np.array([[1/10, 1/5], [1/4, 1]])\n",
    "Y = np.array([[3, 1], [0.1, 0]])\n",
    "Z = np.array([[1, 0], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWCXh9W7zIqy"
   },
   "outputs": [],
   "source": [
    "def their_pipeline(v):\n",
    "    after_W = np.matmul(W, v)\n",
    "    after_X = np.matmul(X, after_W)\n",
    "    after_Y = Y @ after_X\n",
    "    after_Z = Z @ after_Y\n",
    "    return after_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yIcpYfrzTuI"
   },
   "outputs": [],
   "source": [
    "# define V here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dG-0ZLv-A-EK"
   },
   "source": [
    "Run the `grader.grade` cell to check your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtaQdiPh9DTc"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K4j53wEQC0zr"
   },
   "source": [
    "# Section 2. Machine Learning Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array operations, especially matrix multiplications, arise in many places in machine learning.\n",
    "\n",
    "After reviewing how to implement a few simple operations,\n",
    "we'll dive into the _singular value decomposition_,\n",
    "a common method for \"breaking apart\" a single matrix\n",
    "into pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Products and the Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AECzBXMAPOQy"
   },
   "source": [
    "The specific case of matrix multiplication where the first matrix\n",
    "is a row vector and the second is a column vector is also called\n",
    "the _dot product_.\n",
    "For more about the uses of matrix multiplication,\n",
    "including implementations in pure Python,\n",
    "numpy, scipy, and in machine learning frameworks,\n",
    "see the **Appendix** to this notebook..\n",
    "\n",
    "#### Implement the dot product for one-dimensional vectors, represented as lists.\n",
    "\n",
    "Try using one or more `for` loops over the elements in the two vectors.\n",
    "You might also use `zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne6_4h4rTDjg"
   },
   "outputs": [],
   "source": [
    "# implement dot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpDajAVu_oGe"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGA7-1J_1m3x"
   },
   "source": [
    "Dot products show up in lots of places.\n",
    "\n",
    "One is in defining the \"size\" or \"length\" of a vector.\n",
    "In mathematics, this is known as the _norm_ of the vector.\n",
    "\n",
    "There are several different notions of length in linear algebra,\n",
    "but the one that corresponds to the physical or _Euclidean_ length or distance\n",
    "we are familiar with comes directly from the dot product.\n",
    "\n",
    "It is written as $\\|v\\|_2$ for a vector $v$\n",
    "and is defined as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWx8ey6sC0zs"
   },
   "source": [
    "$\\|x\\|_2 = \\sqrt{\\mathrm{dot}(x, x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbuuGX8I2Jfi"
   },
   "source": [
    "#### Use your `dot` function to compute the norm of a `vector` by defining a function called `norm`.\n",
    "\n",
    "Hint: you can calculate square roots with the function `np.sqrt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvP0cN5EC0zt"
   },
   "outputs": [],
   "source": [
    "# implement norm here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHpP1_CaO298"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFTHc5k_2SuE"
   },
   "source": [
    "Norms are often used to _normalize_ vectors,\n",
    "e.g. data vectors,\n",
    "in machine learning.\n",
    "\n",
    "The normalized vector has the same direction as the input vector\n",
    "but has a norm of `1`.\n",
    "\n",
    "It is obtained by dividing the entries in the vector by the vector's norm.\n",
    "\n",
    "#### Define a function, `normalize`, that normalizes an input `vector`.\n",
    "\n",
    "Make sure to re-use your `norm` function!\n",
    "\n",
    "FYI: there's no way to normalize a vector with norm 0,\n",
    "so don't worry about that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhF0BDuIC0zv"
   },
   "outputs": [],
   "source": [
    "# implement normalize here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0xHtuwZBO5HT"
   },
   "outputs": [],
   "source": [
    "grader.grade(\"q07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9_uzirotQfB"
   },
   "source": [
    "# Section 3. Visualizing Linear Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iEueBO2Aj7OX"
   },
   "source": [
    "In two or three dimensions, vectors and linear transformations of vectors\n",
    "can be easily visualized:\n",
    "we can draw a bunch of vectors as points on a two-dimensional screen\n",
    "or in a three-dimensional environment and then _animate_ the transformation.\n",
    "\n",
    "This section does just that,\n",
    "with the aim of building intuition for a bunch of concepts from linear algebra:\n",
    "diagonal matrices, rank, and eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftCT7rjsuxLE"
   },
   "source": [
    "See [this YouTube series by 3blue1brown](https://www.youtube.com/watch?v=F3lG9_SxCXk)\n",
    "for more visualizations of linear algebraic concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vS901_tlOsl"
   },
   "source": [
    "The animations are set up by the `setup_plot` function in the `la.animate` module.\n",
    "\n",
    "Run the cell below to see the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNWHx-DPfGHX"
   },
   "outputs": [],
   "source": [
    "la.animate.setup_plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHT_SNmveatz"
   },
   "source": [
    "### A Collection of Interesting Linear Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5-z3ZuDlZc9"
   },
   "source": [
    "This cell defines several linear transformations that you might want to visualize.\n",
    "\n",
    "You can also define your own linear transformations,\n",
    "so long as they are represented by two-by-two matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUxPYaGpVG8I"
   },
   "outputs": [],
   "source": [
    "eye = [[1, 0],\n",
    "       [0, 1]]\n",
    "\n",
    "scaling1 = [[3, 0],\n",
    "            [0, 3]]\n",
    "\n",
    "scaling2 = [[1/2, 0],\n",
    "            [0, 1/2]]\n",
    "\n",
    "shear = [[1, 2],\n",
    "         [0, 1]]\n",
    "\n",
    "simple_reflection = [[0, 1],\n",
    "                     [1, 0]]\n",
    "\n",
    "negative_reflection = [[0, -1],\n",
    "                       [-1 ,0]]\n",
    "\n",
    "rank0 = [[0, 0],\n",
    "         [0, 0]]\n",
    "\n",
    "rank1 = [[1, 2],\n",
    "         [1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyNkycl7i5BG"
   },
   "source": [
    "### Animating the Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates the animations. See the comments for instructions on use.\n",
    "\n",
    "Some guiding questions appear below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ct_eu0sEboWh"
   },
   "outputs": [],
   "source": [
    "# This line selects the transformation to visualize.\n",
    "transform = shear \n",
    "\n",
    "# This line places a mesh of points to animate:\n",
    "#  either centered at 0 or in the top-right quadrant\n",
    "mesh = la.animate.all_quadrants_mesh\n",
    "# mesh = la.animate.unit_square_mesh\n",
    "\n",
    "# These lines execute the animation code.\n",
    "# If you'd like to see the eigenvectors of a transform,\n",
    "#  change plot_eigenvectors to True\n",
    "\n",
    "f, ax, animate, n_frames = la.animate.setup_plot(\n",
    "    transform,\n",
    "    mesh_properties=mesh,\n",
    "    plot_columns=True,\n",
    "    plot_eigenvectors=False)\n",
    "\n",
    "anim = animation.FuncAnimation(f, animate, frames=n_frames)\n",
    "HTML(anim.to_jshtml(fps=24, default_mode=\"reflect\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pr8UHHtrtbIS"
   },
   "source": [
    "# Appendix: Extra Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a91oDtxhHgfk"
   },
   "source": [
    "## The Matrix Revolution: (almost) Everything is Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7h_DMfMnYxMp"
   },
   "source": [
    "Almost all of the most important operations in linear algebra are based on matrix multiplication.\n",
    "\n",
    "The type signature of matrix multiplication appears below,\n",
    "along with the typical mathematical notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xn8fkxwvd3TE"
   },
   "source": [
    "$$\\mathrm{matmul(x, y)} \\colon \\mathbb{R}^{n \\times m} \\times \\mathbb{R}^{m \\times k} \\rightarrow \\mathbb{R}^{n \\times k}\\\\\n",
    "\\mathrm{matmul}(x, y) = xy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fAgOQ9sZDKH"
   },
   "source": [
    "Each section below demonstrates how a key operation in linear algebra is a form of matrix multiplication.\n",
    "\n",
    "The sections also include implementations in pure Python and in several common data science/machine learning libraries.\n",
    "Some sections also include examples of where these operations show up in machine learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TGAGS-PQo58"
   },
   "source": [
    "### Vector-Vector Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stSyOTYfQyJE"
   },
   "source": [
    "#### Dot Product aka Scalar Product aka Inner Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbZuHDl5LpJ1"
   },
   "source": [
    "$$\n",
    "\\mathrm{dot} \\colon \\mathbb{R}^{n\\times 1} \\times \\mathbb{R}^{n \\times 1} \\rightarrow \\mathbb{R}^{1\\times 1}  \\\\\n",
    "\\mathrm{dot}(x, y) = \\sum_i x_i \\cdot y_i \\\\ \n",
    "\\mathrm{dot}(x, y) = \\mathrm{matmul}(x^\\top, y)= x^\\top y \\\\ \n",
    "\\mathrm{dot}(x, y) = \\langle x , y \\rangle\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpySTJzgIRak"
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "vector1 = [random.normalvariate(0, 1) for _ in range(N)]\n",
    "vector2 = [random.normalvariate(0, 1) for _ in range(N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltcCuhZbRGHG"
   },
   "source": [
    "##### Pure Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7tNHzqWHuCU"
   },
   "outputs": [],
   "source": [
    "def inner_product(vector1, vector2):\n",
    "    result = 0\n",
    "    for element1, element2 in zip(vector1, vector2):\n",
    "        result += element1 * element2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkTrg2J2RP56"
   },
   "source": [
    "##### Numpy Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWMfbncQKfSC"
   },
   "outputs": [],
   "source": [
    "def inner_product_numpy(vector1, vector2):\n",
    "    return np.sum(np.multiply(vector1, vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7L-9HFwK8qV"
   },
   "outputs": [],
   "source": [
    "def inner_product_numpy_matmul(vector1, vector2):\n",
    "    vector1 = np.atleast_2d(vector1)\n",
    "    vector2 = np.atleast_2d(vector2)\n",
    "\n",
    "    return vector1 @ vector2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPtXV2i0dsB3"
   },
   "outputs": [],
   "source": [
    "def inner_product_numpy_dot(vector1, vector2):\n",
    "    return np.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cHVKLyiRVxd"
   },
   "source": [
    "##### TensorFlow and PyTorch Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmuPbqXMKl7U"
   },
   "outputs": [],
   "source": [
    "def inner_product_tf(vector1, vector2):\n",
    "    return tf.reduce_sum(tf.multiply(vector1, vector2)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-7Qow03I44U"
   },
   "outputs": [],
   "source": [
    "def inner_product_tf_tensordot(vector1, vector2):\n",
    "    return tf.tensordot(vector1, vector2, axes=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffJdohPlSvwX"
   },
   "outputs": [],
   "source": [
    "def inner_product_torch(vector1, vector2):\n",
    "    vector1 = torch.Tensor(vector1)\n",
    "    vector2 = torch.Tensor(vector2)\n",
    "\n",
    "    return torch.sum(torch.mul(vector1, vector2)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoYtq2UFRZzd"
   },
   "source": [
    "##### ML Model Examples: Linear Regression, `keras.Dense`, `torch.nn.Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiPO_PfvO5Df"
   },
   "outputs": [],
   "source": [
    "def inner_product_sklearn(vector1, vector2):\n",
    "    regression = sklearn.linear_model.LinearRegression(\n",
    "      fit_intercept=False)\n",
    "\n",
    "    regression.coef_ = np.array(vector1)\n",
    "    regression.intercept_ = 0.\n",
    "\n",
    "    return regression.predict(np.atleast_2d(vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9ea0NuCNf2S"
   },
   "outputs": [],
   "source": [
    "def inner_product_keras(vector1, vector2):\n",
    "    N = len(vector1)\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "      keras.layers.Dense(\n",
    "          1, activation=None, use_bias=False, input_shape=(N,),\n",
    "          kernel_initializer=keras.initializers.Constant(vector1)))\n",
    "\n",
    "    return model.predict([vector2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0vfG9ljU802"
   },
   "outputs": [],
   "source": [
    "def inner_product_torchnn(vector1, vector2):\n",
    "    N = len(vector1)\n",
    "    layer = torch.nn.Linear(N, 1, bias=False)\n",
    "    layer.weight = torch.nn.Parameter(torch.Tensor(vector2))\n",
    "\n",
    "    return layer(torch.Tensor(vector2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rzuDHIeXipj"
   },
   "source": [
    "##### ML Calculation Examples: Norms and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkyJtxUIY-Te"
   },
   "source": [
    "$\\|x\\|_2 = \\sqrt{\\mathrm{dot}(x, x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mS_6uQpQXqzO"
   },
   "outputs": [],
   "source": [
    "def norm(vector):\n",
    "    return np.sqrt(inner_product(vector, vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeC0C8leXzKe"
   },
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    vector_norm = norm(vector)\n",
    "    return [element / vector_norm for element in vector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TPK5ORXaBYL"
   },
   "source": [
    "$$\\cos(\\angle_{x, y}) = \\frac{\\mathrm{dot}(x, y)}{\\|x\\|_2\\cdot\\|y\\|_2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a15Tpk9wXmyG"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    return inner_product(normalize(vector1), normalize(vector2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mP9Zv0IabFTX"
   },
   "source": [
    "#### Outer Product aka Tensor Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgJ73_psbSBA"
   },
   "source": [
    "$$\n",
    "\\mathrm{outer} \\colon \\mathbb{R}^{n \\times 1} \\times \\mathbb{R}^{n \\times 1} \\rightarrow \\mathbb{R}^{n \\times n}  \\\\\n",
    "\\mathrm{outer}(x, y)_{i, j} = x_i \\cdot y_j \\\\ \n",
    "\\mathrm{outer}(x, y) = \\mathrm{matmul}(x, y^\\top) = x y^\\top \\\\\n",
    "\\mathrm{outer}(x, y) = x \\otimes y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVHNppB0cxvX"
   },
   "source": [
    "##### Pure Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YkkTXlUwbJYl"
   },
   "outputs": [],
   "source": [
    "def outer_product(vector1, vector2):\n",
    "    result = []\n",
    "    for ii, element1 in enumerate(vector1):\n",
    "        subresult = []\n",
    "    for jj, element2 in enumerate(vector2):\n",
    "        subresult.append(element1 * element2)\n",
    "    result.append(subresult)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qL6lk8_cbMr"
   },
   "outputs": [],
   "source": [
    "outer_product(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqjH-cNDciug"
   },
   "source": [
    "##### Numpy Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p6Mlrmn-c6z_"
   },
   "outputs": [],
   "source": [
    "def outer_product_numpy(vector1, vector2):\n",
    "    return np.outer(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLeYkL6XdFfb"
   },
   "outputs": [],
   "source": [
    "def outer_product_numpy_matmul(vector1, vector2):\n",
    "    vector1 = np.atleast_2d(vector1)\n",
    "    vector2 = np.atleast_2d(vector2)\n",
    "\n",
    "    return vector1.T @ vector2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlDMb6WQdZ63"
   },
   "outputs": [],
   "source": [
    "outer_product_numpy_matmul(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQvtXRy4ikzd"
   },
   "source": [
    "### Matrix-Vector Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8tj7fcAU0d3"
   },
   "source": [
    "#### Matrix-Vector Multiplication aka Applying Matrices as Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HadJusUWTzfN"
   },
   "source": [
    "Usually, we think of a matrix as a piece of _data_,\n",
    "but we can also think of it as a _function_.\n",
    "\n",
    "When we think of it as a piece of _data_,\n",
    "we often write it mathematically as a\n",
    "\"member of $\\mathbb{R}^{m\\times n}$, the set of arrays\n",
    "with $m$ rows and $n$ columns\", like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0xaG9YGfVci"
   },
   "source": [
    "$$X \\in \\mathbb{R}^{m \\times n}$$\n",
    "\n",
    "As a function, we would write it as \"a function that takes in arrays with $n$ entries and returns arrays with $m$ entries\", or:\n",
    "\n",
    "$$X \\colon \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FET9lA0hfuN5"
   },
   "source": [
    "It's useful to think of some corner cases:\n",
    "what if $m == n == 1$?\n",
    "\n",
    "Then we might have\n",
    "$$ 2 \\in \\mathbb{R}$$\n",
    "or\n",
    "$$ 2 \\colon \\mathbb{R} \\rightarrow \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Qzf-LDFgdIh"
   },
   "source": [
    "where $2(x) = 2x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HlPXEEGUeUi"
   },
   "source": [
    "As indicated by this example,\n",
    "the right notion of what it means to \"apply\" a matrix as a function\n",
    "to a vector must be somehow like mutliplication.\n",
    "\n",
    "In fact, the right method isn't exactly multiplication as we are used to it,\n",
    "because the inputs and outputs aren't the same shape,\n",
    "but it's close enough that it goes by the same name:\n",
    "matrix-vector multiplication.\n",
    "\n",
    "Its type signature and definition are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yCt7ys1Di_Eg"
   },
   "source": [
    "$$\\mathrm{matvec}(X, y) \\colon \\mathbb{R}^{m \\times n} \\times \\mathbb{R}^{n \\times 1} \\rightarrow \\mathbb{R}^{m \\times 1}\\\\\n",
    "\\mathrm{matvec}(X, y) = \\mathrm{matmul}(X, y) = Xy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19KemrmGjmmV"
   },
   "source": [
    "$$\n",
    "\\mathrm{matvec}(X, y)_i = \\sum_j X_{i,j} y_j\\\\\n",
    "\\mathrm{matvec}(X, y)_i = {X_{i, \\colon}} y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BEsfNSGdPR0T"
   },
   "source": [
    "$$\n",
    "\\mathrm{matvec}(X, y) = \\sum_j {X_{\\colon, j}} y_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvLeej95irfN"
   },
   "source": [
    "##### Pure Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UahTVtGkdH8"
   },
   "outputs": [],
   "source": [
    "def matvec(matrix, vector):\n",
    "    result = []\n",
    "    for row in matrix:\n",
    "        result.append(inner_product(row, vector))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEmpnnKDMGL4"
   },
   "outputs": [],
   "source": [
    "def matvec_sum(matrix, vector):\n",
    "    result = []\n",
    "    for ii, row in enumerate(matrix):\n",
    "        result_ii = 0\n",
    "        for jj, element in enumerate(vector):\n",
    "            result_ii += row[jj] * element \n",
    "        result.append(result_ii)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBD7469gkulZ"
   },
   "outputs": [],
   "source": [
    "M = 3\n",
    "matrix = [[random.normalvariate(0, 1) for _ in range(N)] for _ in range(M)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcD9Udz3ktM4"
   },
   "outputs": [],
   "source": [
    "matvec(matrix, vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1YcRnXyNB-Z"
   },
   "outputs": [],
   "source": [
    "matvec_sum(matrix, vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93OAhM_Ok9sA"
   },
   "outputs": [],
   "source": [
    "np.dot(matrix, vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Esyf8eKJLd3n"
   },
   "source": [
    "##### Numpy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OeN9W2mNfZg"
   },
   "outputs": [],
   "source": [
    "def matvec_numpy(matrix, vector):\n",
    "    result = np.zeros_like(np.array(matrix)[:, 0])\n",
    "    for ii, row in enumerate(matrix):\n",
    "        result[ii] = np.sum(np.multiply(row, vector))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNSlz-LtOwze"
   },
   "outputs": [],
   "source": [
    "def matvec_numpy_alternate(matrix, vector):\n",
    "    matrix = np.array(matrix)\n",
    "    result = np.zeros_like(matrix[:, 0])\n",
    "\n",
    "    for jj, column in enumerate(matrix.T):\n",
    "        result += vector[jj] * column\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViH6AUi3lBPA"
   },
   "outputs": [],
   "source": [
    "def matvec_numpy_matmul(matrix, vector):\n",
    "    return np.array(matrix) @ np.array(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOkWFWvwXSvQ"
   },
   "source": [
    "##### Tensorflow and Torch Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FioM6qUXhh5"
   },
   "outputs": [],
   "source": [
    "def matvec_tf(matrix, vector):\n",
    "    return tf.reduce_sum(tf.multiply(matrix, vector), axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RY6zZjuKYFT5"
   },
   "outputs": [],
   "source": [
    "def matvec_tf_tensordot(matrix, vector):\n",
    "    return tf.tensordot(matrix, vector, axes=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwzzQnjLhlU5"
   },
   "source": [
    "Notice that this `tensordot` based implementation is identical to the `inner_product_tf` implementation with `tensordot`. That's because both are just implementing `matmul`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6mf-i-AY9Eq"
   },
   "outputs": [],
   "source": [
    "def matvec_torch(matrix, vector):\n",
    "    matrix = torch.Tensor(matrix)\n",
    "    vector = torch.Tensor(vector)\n",
    "\n",
    "    return torch.sum(torch.mul(matrix, vector), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G91rcKr8a9TJ"
   },
   "source": [
    "##### ML Model Examples: Multiple Linear Regression, `keras.Dense`, `torch.nn.Linear`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ekUPBPo3heQi"
   },
   "source": [
    "Note similarity to dot products above.\n",
    "Not a coincidence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KoDOCdJsaekh"
   },
   "outputs": [],
   "source": [
    "def matvec_sklearn(matrix, vector):\n",
    "    regression = sklearn.linear_model.LinearRegression(\n",
    "      fit_intercept=False)\n",
    "\n",
    "    regression.coef_ = np.array(matrix)\n",
    "    regression.intercept_ = 0.\n",
    "\n",
    "    return regression.predict(np.atleast_2d(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "As09KdXkbMqy"
   },
   "outputs": [],
   "source": [
    "def matvec_keras(matrix, vector):\n",
    "    N, M = len(matrix), len(matrix[0])\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "      keras.layers.Dense(\n",
    "          N, activation=None, use_bias=False, input_shape=(M,),\n",
    "          kernel_initializer=keras.initializers.Constant(np.array(matrix).T)))\n",
    "\n",
    "    return model.predict([vector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDIAbUjfg-6p"
   },
   "source": [
    "Gotcha: `Keras` does all of its matrix multiplications \"from the right\",\n",
    "as in $y^\\top X$ rather than $Xy$,\n",
    "so we need to use the transpose here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJGg2vk3bPRP"
   },
   "outputs": [],
   "source": [
    "def matvec_torchnn(matrix, vector):\n",
    "    N, M = len(matrix), len(matrix[0])\n",
    "    layer = torch.nn.Linear(N, M, bias=False)\n",
    "    layer.weight = torch.nn.Parameter(torch.Tensor(matrix))\n",
    "\n",
    "    return layer(torch.Tensor(vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUH035ymisyY"
   },
   "source": [
    "### Matrix-Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_3uZoUqwMiE"
   },
   "source": [
    "#### Matrix-Matrix Multiplication aka Composing Matrices as Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jP9bmX2ZOVdu"
   },
   "source": [
    "One of the most important features of functions is that they can be **composed**:\n",
    "one function can be applied after another, the output of one used as the input of the next.\n",
    "\n",
    "To compose two functions $f$ and $g$,\n",
    "where\n",
    "\n",
    "$$\n",
    "f\\colon A \\rightarrow B\n",
    "$$\n",
    "and\n",
    "$$\n",
    "g\\colon B \\rightarrow C\n",
    "$$\n",
    "we match the output of one to the inputs of the other,\n",
    "resulting in a new single function,\n",
    "denoted\n",
    "$$\n",
    "g \\circ f \\colon A \\rightarrow C\n",
    "$$\n",
    "where\n",
    "$$\n",
    "g \\circ f(x) = g\\left(f(x)\\right)\n",
    "$$\n",
    "\n",
    "This might be pronounced \"$g$ after $f$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qv8RJ-QziyQZ"
   },
   "source": [
    "Similarly, when we combine, or compose, two matrices $X$ and $Y$,\n",
    "the result is a new matrix, $XY$,\n",
    "which we obtain by multiplying the two matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HiLsQqsxLHdo"
   },
   "source": [
    "$$\\mathrm{matmul(X, Y)} \\colon \\mathbb{R}^{n \\times m} \\times \\mathbb{R}^{m \\times k} \\rightarrow \\mathbb{R}^{n \\times k}\\\\\n",
    "\\mathrm{matmul}(X, Y) = XY = X \\circ Y$$\n",
    "$$\n",
    "\\mathrm{matmul}(X, Y)_{ij} = \\mathrm{matmul}(X_{i, :}, Y_{:, j})\n",
    "$$\n",
    "$$\n",
    "\\mathrm{matmul}(X, Y)_{ij} = \\sum_r X_{i, r} Y_{r, j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OikYDHfqyr3U"
   },
   "outputs": [],
   "source": [
    "N, M, K = 2, 3, 4\n",
    "matrix1 = [[random.normalvariate(0, 1) for _ in range(M)] for _ in range(N)]\n",
    "matrix2 = [[random.normalvariate(0, 1) for _ in range(K)] for _ in range(M)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Y62sVtpv7f0"
   },
   "source": [
    "##### Pure Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSLLDJ9iivxp"
   },
   "outputs": [],
   "source": [
    "def matmul(matrix1, matrix2):\n",
    "    result_array = []\n",
    "    for ii, row in enumerate(matrix1):\n",
    "        result_row = []\n",
    "        for jj in range(len(matrix2[0])):\n",
    "            result = 0\n",
    "            for kk in range(len(matrix2)):\n",
    "                result += matrix1[ii][kk] * matrix2[kk][jj]\n",
    "            result_row.append(result)\n",
    "        result_array.append(result_row)\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBFpRDvRn96S"
   },
   "outputs": [],
   "source": [
    "matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6XqzwF6wZ_T"
   },
   "source": [
    "##### Numpy Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTWE6aHlwcuS"
   },
   "outputs": [],
   "source": [
    "def matmul_numpy(matrix1, matrix2):\n",
    "    return np.array(matrix1) @ np.array(matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly-5EiDnwhZ8"
   },
   "outputs": [],
   "source": [
    "def matmul_numpy_dot(matrix1, matrix2):\n",
    "    return np.dot(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBKr6Mjwwmwb"
   },
   "outputs": [],
   "source": [
    "def matmul_numpy_matmul(matrix1, matrix2):\n",
    "    return np.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MxeNjqhw0wo"
   },
   "outputs": [],
   "source": [
    "matmul_numpy(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-26dpoNx1ux"
   },
   "outputs": [],
   "source": [
    "matmul_numpy_dot(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0affHd0Lx3s7"
   },
   "outputs": [],
   "source": [
    "matmul_numpy_matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCfStwcPy43U"
   },
   "source": [
    "##### Tensorflow and PyTorch Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9749vRtP0RHS"
   },
   "outputs": [],
   "source": [
    "def matmul_tf(matrix1, matrix2):\n",
    "    return tf.matmul(matrix1, matrix2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yMPWF13zHOk"
   },
   "outputs": [],
   "source": [
    "def matmul_tf_tensordot(matrix1, matrix2):\n",
    "    return tf.tensordot(matrix1, matrix2, axes=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skWXzh7QzLFL"
   },
   "outputs": [],
   "source": [
    "matmul_tf_tensordot(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLlbzgb83Mr8"
   },
   "outputs": [],
   "source": [
    "def matmul_torch(matrix1, matrix2):\n",
    "    matrix1 = torch.Tensor(matrix1)\n",
    "    matrix2 = torch.Tensor(matrix2)\n",
    "\n",
    "    return torch.matmul(matrix1, matrix2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VD8oFk9v0fA4"
   },
   "outputs": [],
   "source": [
    "def matmul_torch_tensordot(matrix1, matrix2):\n",
    "    matrix1 = torch.Tensor(matrix1)\n",
    "    matrix2 = torch.Tensor(matrix2)\n",
    "\n",
    "    return torch.tensordot(matrix1, matrix2, dims=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_TzC1e2A0t3M"
   },
   "outputs": [],
   "source": [
    "matmul_torch(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVvAQWST4RJO"
   },
   "outputs": [],
   "source": [
    "matmul_torch_tensordot(matrix1, matrix2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qOvkwqdHHKQ2",
    "K4j53wEQC0zr",
    "K9_uzirotQfB",
    "SHT_SNmveatz",
    "uyNkycl7i5BG",
    "a91oDtxhHgfk",
    "5TGAGS-PQo58",
    "bQvtXRy4ikzd",
    "G8tj7fcAU0d3",
    "LvLeej95irfN",
    "Esyf8eKJLd3n",
    "uOkWFWvwXSvQ",
    "G91rcKr8a9TJ",
    "BUH035ymisyY",
    "m_3uZoUqwMiE",
    "5Y62sVtpv7f0",
    "o6XqzwF6wZ_T"
   ],
   "name": "Colab - Math4ML I: Linear Algebra",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
